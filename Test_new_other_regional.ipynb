{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ec5d13b-2fc7-4640-9c9d-a0c1c617ec5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from components.data_prep import *\n",
    "from components.preprocess import *\n",
    "from components.config import *\n",
    "from components.helper import *\n",
    "from model.nn import*\n",
    "\n",
    "cdp_path='/dbfs/mnt/cdpprod/Customer_Profile_Aggregates/'\n",
    "mgm_reward = spark.read.parquet('dbfs:/mnt/proddatalake/prod/CFA/CFA_overall_lvl')\n",
    "rc = spark.read.format(\"delta\").load('dbfs:/mnt/edhprodenrich/Enterprise Data Store/Secured/data/Cleanse/RCX/RCX_enums/CurrentState')\n",
    "la = spark.read.format(\"delta\").load(\"dbfs:/mnt/edhprodenrich/Enterprise Data Store/Secured/data/Cleanse/RCX/RCX_loyalty_activities/CurrentState\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21f267c6-7ef8-4855-ac73-34ed6fbef280",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "regional = 'Borgata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0699a49b-280a-4834-8d94-a3e3d425779a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "yesterday=str(max(os.listdir(cdp_path)))\n",
    "\n",
    "trip_data = spark.read.parquet('dbfs:/mnt/cdpprod/Customer_Profile_Aggregates/'+yesterday+'/')\\\n",
    "            .withColumn('Site', F.when(F.col('SiteGroup') == 'LAS', 'Vegas').otherwise('Region'))\\\n",
    "            .filter(F.col('Mnth')>='2016-01-01')\\\n",
    "            .filter((F.col('TripRvMgmt_Segment')!='Convention')|F.col('TripRvMgmt_Segment').isNull())\n",
    "trip_data = trip_data.withColumn(\"TripID\",F.concat(F.col(\"Guest_ID\"),F.lit('_'), F.col(\"TripStart\"),F.lit('_'),F.col(\"TripEnd\")))\n",
    "\n",
    "CPA = trip_data.where(\"property_name != 'BetMGM' and tripstart < '2024-12-31'\").select('guest_id','Property_Name','Department','TripStart','TripEnd','TripStartMlifeTier', 'TripGamingDays','TripID')\n",
    "trip_CPA = CPA.groupBy('guest_id','TripStart','TripEnd', 'TripID').agg(F.count('Department').alias('dept_num'), F.max('Property_Name').alias('property_name'),\n",
    "                                                                              F.max('TripGamingDays').alias('TripGamingDays'), F.max('TripStartMlifeTier').alias('TripStartMlifeTier'))\n",
    "trip_borgata = trip_CPA.where(F.col('property_name').contains(regional))\n",
    "trip_borgata_2022 = trip_borgata.where('TripStart between \"2022-01-01\" and \"2022-12-31\"')\n",
    "trip_borgata_2023 = trip_borgata.where('TripStart between \"2023-01-01\" and \"2023-12-31\"')\n",
    "trip_borgata_2024 = trip_borgata.where('TripStart between \"2024-01-01\" and \"2024-12-31\"')\n",
    "# Players need to have trip in either 2022 or 2023\n",
    "hist_spec = trip_borgata_2022.union(trip_borgata_2023).select('guest_id').distinct()\n",
    "#trip_spec = trip_borgata_2024.join(hist_spec, on='guest_id', how='inner').select('guest_id').distinct()\n",
    "# 2023 only\n",
    "trip_spec = trip_borgata_2024.join(trip_borgata_2023, on='guest_id', how='inner').select('guest_id').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d85a057-6a82-4111-9713-46d2058c657c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "trip_spec_2024 = trip_borgata_2024.join(trip_borgata_2023, on='guest_id', how='inner').select('guest_id').distinct()\n",
    "new_trip = trip_borgata_2024.join(trip_spec_2024, on = 'guest_id', how = 'leftanti')\n",
    "\n",
    "tc_2023 = spark.read.parquet(f'dbfs:/mnt/proddatalake/dev/RCX/TC_2023.parquet')\n",
    "tc_2024 = spark.read.parquet(f'dbfs:/mnt/proddatalake/dev/RCX/TC_2024.parquet')\n",
    "\n",
    "tc_2024 = tc_2024.groupBy('playerid').agg(\n",
    "    F.sum('tiercredit').alias('total_tc'), \n",
    "    F.sum(F.when(F.col('site_name').contains(regional), F.col('tiercredit')).otherwise(F.lit(0))).alias('regional_tc')\n",
    ")\n",
    "tc_2024 = tc_2024.join(mgm_reward, F.col('playerid') == F.col('MLifeID'), how='inner').select(*tc_2024.columns, 'guest_id')\n",
    "\n",
    "# Filtering Borgata Dominant Players\n",
    "regional_dominant_players = tc_2024.where('regional_tc > 0.8').select('guest_id')\n",
    "trip = new_trip.join(regional_dominant_players, on='guest_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c26722a7-094f-4f3b-9e88-b6eb0f3c466c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "TM = spark.read.parquet('dbfs:/mnt/proddatalake/dev/RCX/Tier_History.parquet').where('year(change_assigned) = 2024')\n",
    "TM = TM.join(mgm_reward, TM.playerid == mgm_reward.MLifeID, how='inner').select('guest_id','change_assigned','tier_before_change','tier_after_change')\n",
    "TM = TM.join(trip.select('guest_id').distinct(), on='guest_id',how='inner').select('guest_id','change_assigned','tier_before_change','tier_after_change').withColumn('tier_before', F.when(F.col('tier_before_change') == 'Sapphire', F.lit(1)).when(F.col('tier_before_change') == 'Pearl', F.lit(2)).when(F.col('tier_before_change') == 'Gold', F.lit(3)).when(F.col('tier_before_change') == 'Platinum', F.lit(4)).otherwise(5)) \\\n",
    "        .withColumn('tier_after', F.when(F.col('tier_after_change') == 'Sapphire', F.lit(1)).when(F.col('tier_after_change') == 'Pearl', F.lit(2)).when(F.col('tier_after_change') == 'Gold', F.lit(3)).when(F.col('tier_after_change') == 'Platinum', F.lit(4)).otherwise(5))\n",
    "TM.where('tier_before < tier_after').select(F.countDistinct('guest_id')).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02823d05-8b33-4dd7-833a-a8cd22961b21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "temp = TC_trip_formulation_daily_model(2024, trip, spark)\n",
    "temp_train = temp.groupby('guest_id','calendar_year','change_assigned').agg(\n",
    "    F.count('*').alias('trip_num'), \n",
    "    F.sum('TotalTierCredit').alias('TotalTierCredit'),\n",
    "    F.sum('gaming_tc').alias('gaming_tc'),\n",
    "    F.sum('non_gaming_tc').alias('non_gaming_tc'),\n",
    "    F.min('tier').alias('tier'),\n",
    "    F.max('tier_before').alias('pro_tier'),\n",
    "    F.max('mt_reason').alias('reason_code'),\n",
    "    F.max('mt_subreason').alias('subreason_code'),\n",
    "    F.max('mth_reason').alias('mth_reason_code'),\n",
    "    F.max('mth_subreason').alias('mth_subreason_code'),\n",
    "    F.max('tier_after').alias('tier_after')\n",
    ").withColumn(\n",
    "    'trip_tier',\n",
    "    F.coalesce('pro_tier', F.substring(\"tier\", 2, 2).cast('int'))\n",
    ").withColumn(\n",
    "    'target_TC', \n",
    "    F.when(F.col('trip_tier')==1, 20000)\n",
    "    .when(F.col('trip_tier')==2, 75000)\n",
    "    .when(F.col('trip_tier')==3, 200000)\n",
    "    .otherwise(-1)\n",
    ").filter('target_tc != -1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "243c779d-b3e6-4289-891c-cf576e76e5a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "year = 2024\n",
    "TC = spark.read.parquet(f'dbfs:/mnt/proddatalake/dev/RCX/TC_{year}.parquet')\n",
    "temp_train_daily = get_train_daily_new(TC, 2024, temp, temp_train, mgm_reward, rc, la)\n",
    "\n",
    "window_spec = Window.partitionBy('train_guest_id').orderBy('transactiondate').rowsBetween(Window.unboundedPreceding, 0)\n",
    "\n",
    "temp_train_daily = temp_train_daily.withColumn(\n",
    "    \"lodger_percentage\",\n",
    "    (F.sum(F.when(F.col('TripLodgingStatus')==1, 1).otherwise(0)).over(window_spec) / F.row_number().over(window_spec))\n",
    ").withColumn(\n",
    "    \"local_percentage\",\n",
    "    (F.sum(F.when(F.col('TripLodgingStatus')==2, 1).otherwise(0)).over(window_spec) / F.row_number().over(window_spec))\n",
    ")\n",
    "\n",
    "temp_train_daily = temp_train_daily.distinct()\n",
    "\n",
    "error= temp_train_daily.where('cuml_tc > target_tc and (transactiondate != change_assigned or change_assigned is null)').select('train_guest_id').distinct()\n",
    "new_train_daily = temp_train_daily.join(error, on = 'train_guest_id', how='leftanti')\n",
    "\n",
    "#temp_train_daily = temp_train_daily.where('(change_assigned != transactiondate) or change_assigned is null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b40e8504-615a-4f6c-82da-c04ea06bd283",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "temp_train_daily.join(error, on = 'train_guest_id', how='inner').where('train_guest_id = 78151882').display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "085515a2-0668-4092-b749-5289eaf3454b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "scaler_model_path = \"models:/data_science_mart.tierimminent_cleaned.minmax_scaler_borgata_new@active\"\n",
    "minmax_scalar_new, train = train_minmax(new_train_daily, FEATURE_NAMES_NEW)\n",
    "#train = apply_minmax(new_train_daily, FEATURE_NAMES_NEW, scaler_model_path)\n",
    "train.write.mode(\"overwrite\").parquet('/mnt/proddatalake/dev/TierImminent/data/BR_new_scaled_test.parquet')\n",
    "t = spark.read.parquet('dbfs:/mnt/proddatalake/dev/TierImminent/data/BR_new_scaled_test.parquet')\n",
    "\n",
    "# unsucess_id = t.groupby('train_guest_id').agg(F.count('change_assigned').alias('count')).where('count = 0').sample(withReplacement=False, fraction=0.5, seed=269)\n",
    "# train_final = t.join(unsucess_id, on = 'train_guest_id', how='leftanti').select(*train.columns)\n",
    "train_final = t.where('(change_assigned != transactiondate) or change_assigned is null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30c0f506-900f-40b4-86d4-07dd2d04d083",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "t.describe().display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccb6a79b-0745-4104-b710-56b28cebc6c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loaded_model = mlflow.pytorch.load_model(f\"models:/data_science_mart.tierimminent_cleaned.borgata_lstm_model_new@active\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c38f308a-b6bf-43e0-b067-725b2e1a0a89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# outputs_ls, labels_ls, y_pred_ls_2, y_pred_ls_5, y_pred_ls_35 = [], [], [], [], []\n",
    "outputs_ls = []\n",
    "labels_ls = []\n",
    "remaining_ls = []\n",
    "new_outputs_ls = []\n",
    "id_ls = []\n",
    "X, y, l = None, np.array([]), np.array([])\n",
    "tier = pd.DataFrame(columns=['id','remaining_dyas','tier'])\n",
    "features_scaled = []\n",
    "for j in range(len(FEATURE_NAMES_NEW)):\n",
    "    features_scaled.append(FEATURE_NAMES_NEW[j]+'_scaled')\n",
    "for i in tqdm(range(365, 0, -1)):\n",
    "    cus_list = train_final.filter(train_final.remaining_days == i).select(F.col('train_guest_id').alias('id')).distinct()\n",
    "    temp_df = train_final.join(cus_list, (train_final.train_guest_id == cus_list.id) & (train_final.remaining_days >= i), how = 'inner')\n",
    "    temp_df = temp_df.withColumn('rn', F.row_number().over(Window.partitionBy('train_guest_id').orderBy('remaining_days'))).where('rn <= 6')\n",
    "    # t = temp_df.groupby('train_guest_id','remaining_days').agg(F.min('target_tc').alias('tier')).where(f'remaining_days == {i}')\n",
    "    # t = t.toPandas()\n",
    "    # tier = pd.concat([tier, t], ignore_index=True)\n",
    " \n",
    "    train_np, label, length, train_id = create_sequences_and_labels(temp_df, features_scaled, 6)\n",
    "    if X is None:\n",
    "        X = train_np\n",
    "    else:\n",
    "        X = np.append(X, train_np, axis = 0)\n",
    "    y = np.append(y, label)\n",
    "    l = np.append(l, length)\n",
    "    \n",
    "    # X = torch.tensor(train_np, dtype=torch.float32).cpu()\n",
    "    # len_X = torch.tensor(length, dtype=torch.float32).cpu()\n",
    "    # with torch.no_grad():\n",
    "    #     outputs = loaded_model(X, len_X).squeeze()\n",
    "    # outputs = torch.sigmoid(outputs)\n",
    "\n",
    "    test_X = torch.tensor(train_np, dtype=torch.float32).cpu()\n",
    "    len_X = torch.tensor(length, dtype=torch.float32).cpu()\n",
    "    with torch.no_grad():\n",
    "        new_outputs = loaded_model(test_X, len_X).squeeze()\n",
    "\n",
    "    new_outputs = torch.sigmoid(new_outputs)\n",
    "\n",
    "\n",
    "    # y_pred_2 = [1 if prob >= 0.2 else 0 for prob in outputs]\n",
    "    # y_pred_5 = [1 if prob >= 0.5 else 0 for prob in outputs]\n",
    "    # y_pred_35 = [1 if prob >= 0.35 else 0 for prob in outputs]\n",
    "\n",
    "    # for i, p in zip(train_id, y_pred):\n",
    "    #     if p == 1:\n",
    "    #         if i in output_dict:\n",
    "    #             output_dict[i] += 1\n",
    "    #         else:\n",
    "    #             output_dict[i] = 1\n",
    "                                                                                                                                                              \n",
    "    # y_pred_ls_2.extend(y_pred_2)  \n",
    "    # y_pred_ls_5.extend(y_pred_5)\n",
    "    # y_pred_ls_35.extend(y_pred_35)\n",
    "    # outputs_ls.extend(outputs)\n",
    "    # labels_ls.extend(label)\n",
    "    # id_ls.extend(train_id)\n",
    "    # remaining_ls.extend([i]*len(label))\n",
    "    new_outputs_ls.extend(new_outputs)\n",
    "    labels_ls.extend(label)\n",
    "    id_ls.extend(train_id)\n",
    "    remaining_ls.extend([i]*len(label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39aebbaf-d99f-4a84-89ec-5553d8c3d870",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(labels_ls, new_outputs_ls)\n",
    "auc_score = roc_auc_score(labels_ls, new_outputs_ls)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {auc_score:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guess\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "for i in range(0, len(thresholds), len(thresholds)//20):\n",
    "    plt.text(fpr[i], tpr[i], f'{thresholds[i]:.2f}', fontsize=8, color='red')\n",
    "#plt.savefig(\"/Workspace/Users/609399@mgmresorts.com/Tier Imminent/model_performance_metric/sim_2024_roc.png\")\n",
    "plt.show()\n",
    "plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6f4364f-3b9b-46f3-920c-72dd720edcb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(labels_ls, new_outputs_ls)\n",
    "auc_score = roc_auc_score(labels_ls, new_outputs_ls)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {auc_score:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guess\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "for i in range(0, len(thresholds), len(thresholds)//20):\n",
    "    plt.text(fpr[i], tpr[i], f'{thresholds[i]:.2f}', fontsize=8, color='red')\n",
    "#plt.savefig(\"/Workspace/Users/609399@mgmresorts.com/Tier Imminent/model_performance_metric/sim_2024_roc.png\")\n",
    "plt.show()\n",
    "plt.close() "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Test_new_other_regional",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
